{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool is used to annotate links. The tool is configured to annotate fb15k and dbpedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, specify the paths of the test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy\n",
    "import copy\n",
    "import torch\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, Layout, ButtonStyle\n",
    "from IPython.display import Markdown\n",
    "import requests\n",
    "from time import sleep\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import urllib\n",
    "from functools import cmp_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_name = 'fb15k237'\n",
    "main_folder = './binary-embeddings/' + db_name + '/'\n",
    "annotations_file = main_folder + \"annotations/gold-annotations.json\"\n",
    "testdata_raw_path = '../benchmarks/' + db_name + '/test2id.txt'\n",
    "annotator = 'J'\n",
    "mode = 1 # If the mode is 0, then we always try to select new queries first. If it's 1, we will select queries already annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testdata_folder = main_folder + 'answers/'\n",
    "testdata_transe_path_head = testdata_folder + db_name + '-answers-transe-test-10-head.pkl'\n",
    "testdata_transe_path_tail = testdata_folder + db_name + '-answers-transe-test-10-tail.pkl'\n",
    "testdata_complex_path_head = testdata_folder + db_name + '-answers-complex-test-10-head.pkl'\n",
    "testdata_complex_path_tail = testdata_folder + db_name + '-answers-complex-test-10-tail.pkl'\n",
    "testdata_rotate_path_head = testdata_folder + db_name + '-answers-rotate-test-10-head.pkl'\n",
    "testdata_rotate_path_tail = testdata_folder + db_name + '-answers-rotate-test-10-tail.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ent_labels_path = '../benchmarks/%s/entity2id.txt' % db_name\n",
    "rel_labels_path = '../benchmarks/%s/relation2id.txt' % db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ent_labels = {}\n",
    "with open(ent_labels_path, 'rt') as f:\n",
    "    nents = int(f.readline())\n",
    "    for line in f:\n",
    "        tkns = line.split('\\t')\n",
    "        ent_labels[int(tkns[1])] = tkns[0]\n",
    "    assert(len(ent_labels) == nents)\n",
    "rel_labels = {}\n",
    "with open(rel_labels_path, 'rt') as f:\n",
    "    nrels = int(f.readline())\n",
    "    for line in f:\n",
    "        tkns = line.split('\\t')\n",
    "        rel_labels[int(tkns[1])] = tkns[0]\n",
    "    assert(len(rel_labels) == nrels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the raw test triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_test_triples = set()\n",
    "with open(testdata_raw_path, 'rt') as f:\n",
    "    nfacts = int(f.readline())\n",
    "    for l in f:\n",
    "        tkns = l.split(' ')\n",
    "        h = int(tkns[0])\n",
    "        t = int(tkns[1])\n",
    "        r = int(tkns[2])\n",
    "        raw_test_triples.add((h, t, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(testdata_transe_path_head, 'rb') as fin:\n",
    "    testdata_transe_head = pkl.load(fin)\n",
    "with open(testdata_transe_path_tail, 'rb') as fin:\n",
    "    testdata_transe_tail = pkl.load(fin)\n",
    "with open(testdata_complex_path_head, 'rb') as fin:\n",
    "    testdata_complex_head = pkl.load(fin)\n",
    "with open(testdata_complex_path_tail, 'rb') as fin:\n",
    "    testdata_complex_tail = pkl.load(fin)\n",
    "with open(testdata_rotate_path_head, 'rb') as fin:\n",
    "    testdata_rotate_head = pkl.load(fin)\n",
    "with open(testdata_rotate_path_tail, 'rb') as fin:\n",
    "    testdata_rotate_tail = pkl.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute all the head and tail queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries_tail = {}\n",
    "for name, testset in [(\"transe\", testdata_transe_tail), (\"complex\", testdata_complex_tail), (\"rotate\", testdata_rotate_tail)]:\n",
    "    for t in testset:\n",
    "        ent = t['ent']\n",
    "        rel = t['rel']\n",
    "        if (ent, rel) in queries_tail:\n",
    "            answers = queries_tail[(ent, rel)]\n",
    "            if name not in answers:\n",
    "                answers[name] = t['answers_fil']\n",
    "        else:\n",
    "            a = { name : t['answers_fil'] }            \n",
    "            queries_tail[(ent, rel)] = a\n",
    "\n",
    "queries_head = {}\n",
    "for name, testset in [(\"transe\", testdata_transe_head), (\"complex\", testdata_complex_head), (\"rotate\", testdata_rotate_head)]:\n",
    "    for t in testset:\n",
    "        ent = t['ent']\n",
    "        rel = t['rel']    \n",
    "        if (ent, rel) in queries_head:\n",
    "            answers = queries_head[(ent, rel)]\n",
    "            if name not in answers:\n",
    "                answers[name] = t['answers_fil']\n",
    "        else:\n",
    "            a = { name : t['answers_fil'] }           \n",
    "            queries_head[(ent, rel)] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy all the queries into a single list. Also, load all the queries previously annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Queries: 22850\n"
     ]
    }
   ],
   "source": [
    "queries = []\n",
    "counter = 0\n",
    "for q, a in queries_head.items():\n",
    "    queries.append({'id': counter, 'type': 0, 'ent' : q[0], 'rel' : q[1], 'answers' : a})\n",
    "    counter += 1    \n",
    "for q, a in queries_tail.items():\n",
    "    queries.append({'id': counter, 'type': 1, 'ent' : q[0], 'rel' : q[1], 'answers' : a})    \n",
    "    counter += 1\n",
    "print(\"# Queries:\", len(queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations from file ./binary-embeddings/fb15k237/annotations/gold-annotations.json\n",
      "# Processed Queries: 260  # valid: 250\n"
     ]
    }
   ],
   "source": [
    "out = widgets.Output(layout={'padding': '5px', 'border': '1px solid black'})\n",
    "array_answers = []\n",
    "valid_annotations = True\n",
    "current_query_id = None\n",
    "processed_queries = {}\n",
    "n_valid_queries = 0\n",
    "if os.path.exists(annotations_file):\n",
    "    print(\"Loading annotations from file\", annotations_file)\n",
    "    processed_queries = json.load(open(annotations_file, 'rt'))\n",
    "    new_processed_queries = {}\n",
    "    for k, v in processed_queries.items():\n",
    "        new_processed_queries[int(k)] = v\n",
    "        if v['valid_annotations'] == True:\n",
    "            n_valid_queries += 1\n",
    "    processed_queries = new_processed_queries\n",
    "print(\"# Processed Queries:\", len(processed_queries), \" # valid:\", n_valid_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pick_next_query():\n",
    "    global current_query_id\n",
    "    global processed_queries\n",
    "    if mode == 0:\n",
    "        if len(processed_queries) < len(queries):            \n",
    "            n_attempts = 10\n",
    "            attempt = 0\n",
    "            found = False\n",
    "            while attempt < n_attempts:\n",
    "                idx = random.randint(0, len(queries) - 1)\n",
    "                if idx not in processed_queries:\n",
    "                    found = True\n",
    "                    break\n",
    "                attempt += 1\n",
    "            if found:\n",
    "                current_query_id = idx\n",
    "            else:\n",
    "                # Pick the first ID that is not in processed_queries\n",
    "                for i in range(len(queries)):\n",
    "                    if i not in processed_queries:\n",
    "                        found = True\n",
    "                        current_query_id = i\n",
    "                        break\n",
    "                assert(found)\n",
    "            return True        \n",
    "        else:\n",
    "            return None\n",
    "    else: # mode=1\n",
    "        # First pick a query not annotated by the current annotator\n",
    "        for key, query in processed_queries.items():\n",
    "            annotated_answers = query['annotated_answers']\n",
    "            found = False\n",
    "            for annotated_answer in annotated_answers:\n",
    "                c = annotated_answer['checked']\n",
    "                for annotation in c:\n",
    "                    if annotation['annotator'] == annotator:                        \n",
    "                        found = True\n",
    "                        break\n",
    "            if not found:\n",
    "                # Good, found one\n",
    "                current_query_id = key\n",
    "                return True\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def on_change_checkbox(b):\n",
    "    owner = b['owner']\n",
    "    desc = owner.description\n",
    "    id_answer = int(owner.description[0:desc.find('.')])\n",
    "    value = b['new']\n",
    "    found = False\n",
    "    for ans_annotator in array_answers[id_answer]['checked']:\n",
    "        if ans_annotator['annotator'] == annotator:\n",
    "            found = True        \n",
    "            if value is True:\n",
    "                ans_annotator['checked'] = True\n",
    "            else:\n",
    "                ans_annotator['checked'] = False\n",
    "            break\n",
    "    assert(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dump_on_file():\n",
    "    # First check if the file exist\n",
    "    if os.path.exists(annotations_file):\n",
    "        now = str(datetime.datetime.now())\n",
    "        old_file = annotations_file + '-' + now\n",
    "        os.rename(annotations_file, old_file)\n",
    "    json.dump(processed_queries, open(annotations_file, 'wt'), indent = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def on_click_button(b):\n",
    "    global processed_queries\n",
    "    global current_query_id\n",
    "    global valid_annotations\n",
    "    \n",
    "    out.clear_output()\n",
    "    # Store the annotation\n",
    "    query = queries[current_query_id]\n",
    "    if current_query_id in processed_queries:\n",
    "        annotators = processed_queries[current_query_id]['annotators']\n",
    "    else:\n",
    "        annotators = []\n",
    "    annotators.append({'annotator' : annotator, 'date' : str(datetime.datetime.now()) })\n",
    "    processed_queries[current_query_id] = {'query' : query, 'valid_annotations' : valid_annotations, 'annotated_answers' : array_answers, 'annotators' : annotators }\n",
    "    dump_on_file()\n",
    "    \n",
    "    # Move to the next query\n",
    "    with out:\n",
    "        ok = pick_next_query()\n",
    "        if ok is not None:\n",
    "            query = queries[current_query_id]\n",
    "            print_query_answers(query['id'], query['type'], query['ent'], query['rel'], query['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def on_click_skip_button(b):\n",
    "    global valid_annotations\n",
    "    valid_annotations = False\n",
    "    on_click_button(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_wikidata_label(e):\n",
    "    # Query Wikidata\n",
    "    try:\n",
    "        query = 'PREFIX wd: <http://www.wikidata.org/entity/> ' + 'PREFIX wdt: <http://www.wikidata.org/prop/direct/> ' + \"SELECT ?x ?xLabel WHERE { ?x wdt:P646 \\\"\" + e + \"\\\"; SERVICE wikibase:label { bd:serviceParam wikibase:language \\\"[AUTO_LANGUAGE],en\\\". } }\"\n",
    "        r = requests.get('https://query.wikidata.org/bigdata/namespace/wdq/sparql', params = {'format': 'json', 'query': query})\n",
    "        if r:\n",
    "            r = r.json()\n",
    "            results = r['results']\n",
    "            bindings = results['bindings']\n",
    "            # Take the first\n",
    "            binding = bindings[0]\n",
    "            value = binding['x']['value']\n",
    "            lbl = binding['xLabel']['value']\n",
    "            return lbl, value\n",
    "    except:\n",
    "        pass\n",
    "    return 'None', 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_query_answers(query_id, typ, ent, rel, answers):\n",
    "    global processed_queries\n",
    "    global array_answers\n",
    "    global valid_annotations\n",
    "    valid_annotations = True\n",
    "    n_skipped = 0\n",
    "    n_ok = 0\n",
    "    n_annotated_answers = 0\n",
    "    n_tail_queries = 0\n",
    "    n_head_queries = 0\n",
    "    for _, q in processed_queries.items():\n",
    "        if q['valid_annotations']:\n",
    "            n_ok += 1\n",
    "            n_annotated_answers += len(q['annotated_answers'])\n",
    "            if q['query']['type'] == 1:\n",
    "                n_tail_queries += 1\n",
    "            else:\n",
    "                n_head_queries += 1\n",
    "        else:\n",
    "            n_skipped += 1\n",
    "    print(\"Processed queries: {} Skipped: {} Ok: {} Head: {} Tail: {}\".format(len(processed_queries), n_skipped, n_ok, n_head_queries, n_tail_queries))\n",
    "    print(\"Annnotated answers: {}\\n\".format(n_annotated_answers))\n",
    "    typ_str = 'HEAD'\n",
    "    if typ == 1:\n",
    "        typ_str = 'TAIL'\n",
    "    display(Markdown(\"***Query #{} Type {}***\".format(query_id, typ_str)))\n",
    "    if db_name == 'fb15k237':\n",
    "        lbl, link_wikidata = retrieve_wikidata_label(ent_labels[ent])\n",
    "        ent_str = '[' + lbl + ' ' + link_wikidata + ' (' + ent_labels[ent] + ')]'   \n",
    "    else:\n",
    "        lbl, link_wikidata = (ent_labels[ent], \"\")\n",
    "        ent_str = lbl\n",
    "    if typ == 0:\n",
    "        print(\"?\", rel_labels[rel], ent_str)\n",
    "    else:\n",
    "        print(ent_str, rel_labels[rel], \"?\")\n",
    "    \n",
    "    previous_annotations = None\n",
    "    array_answers = []\n",
    "    if mode == 1 and query_id in processed_queries:\n",
    "        print(\"\\nThis query was previously annotated by\" + str(processed_queries[query_id]['annotators']))\n",
    "        previous_annotations = processed_queries[query_id]['annotated_answers']\n",
    "        array_answers = copy.deepcopy(previous_annotations)\n",
    "\n",
    "    lbl_google = urllib.parse.urlencode({\"q\" : lbl})\n",
    "    google_link = \"https://www.google.com/search?hl=en&\" + lbl_google\n",
    "    display(Markdown(\"***Search on Google:*** {}\".format(google_link)))\n",
    "    print(\"\\nAnswers (striked answers are the ones that are in the testset):\")    \n",
    "    for method, answers_method in answers.items():\n",
    "        for i, answer in enumerate(answers_method):\n",
    "            a = answer['entity_id']\n",
    "            # Should I add it?\n",
    "            found = False\n",
    "            for j, array_answer in enumerate(array_answers):\n",
    "                if array_answer['entity_id'] == a:\n",
    "                    found = True\n",
    "                    # add the method if not already there\n",
    "                    method_found = False                    \n",
    "                    for m in array_answer['methods']:\n",
    "                        if m == method:\n",
    "                            method_found = True\n",
    "                            break\n",
    "                    if not method_found:\n",
    "                        array_answer['methods'].append(method)\n",
    "                    # Add an entry with the current annotator if it does not exist\n",
    "                    annotator_found = False\n",
    "                    for c in array_answer['checked']:\n",
    "                        if c['annotator'] == annotator:\n",
    "                            annotator_found = True\n",
    "                            break\n",
    "                    if not annotator_found and array_answer['enabled']:\n",
    "                        array_answer['checked'].append({'annotator' : annotator, 'checked' : False })\n",
    "                    break                    \n",
    "            if not found:              \n",
    "                # Is the answer known to be true?\n",
    "                found = False\n",
    "                if typ == 0 and (a, ent, rel) in raw_test_triples:\n",
    "                    found = True\n",
    "                if typ == 1 and (ent, a, rel) in raw_test_triples:\n",
    "                    found = True\n",
    "                if found:\n",
    "                    array_answers.append({'entity_id' : a, 'checked' : [{'annotator' : 'Testset', 'checked' : True }], 'methods': [method], 'enabled' : False})\n",
    "                else:\n",
    "                    # If mode==1, I'm hiding the previous annotations so that two different annotators may annotate with different values\n",
    "                    array_answers.append({'entity_id' : a, 'checked' : [{'annotator' : annotator, 'checked' : False }], 'methods': [method], 'enabled' : True})\n",
    "                        \n",
    "    for i, a in enumerate(array_answers):\n",
    "        if db_name == 'fb15k237':\n",
    "            sleep(1) # Some sleeping is necessary for wikidata            \n",
    "            lbl, link_wikidata = retrieve_wikidata_label(ent_labels[a['entity_id']])\n",
    "        else:\n",
    "            lbl, link_wikidata = (ent_labels[a['entity_id']],'')\n",
    "        a_str = lbl\n",
    "        desc = \"{}. {} ({}) methods={}\".format(i, a_str, a['entity_id'], a['methods'])\n",
    "        if a['enabled'] == False:\n",
    "            assert(a['checked'][0]['annotator'] == 'Testset')\n",
    "            assert(a['checked'][0]['checked'] == True)\n",
    "            box = widgets.Checkbox(True, id=i, description=\"<strike>\" + desc + \"</strike>\", layout=Layout(width='2000px', height='20px'), indent=False, disabled=True)\n",
    "        else:\n",
    "            box = widgets.Checkbox(False, id=i, description=desc, layout=Layout(width='2000px', height='20px'), indent=False)\n",
    "        box.observe(on_change_checkbox, names=\"value\")\n",
    "        display(box)\n",
    "        if a['enabled'] == True:\n",
    "            lbl_google = urllib.parse.urlencode({\"q\" : lbl})\n",
    "            google_link = \"https://www.google.com/search?hl=en&\" + lbl_google\n",
    "            lbl_wikipedia = urllib.parse.urlencode({\"search\" : lbl})\n",
    "            wikipedia_link = \"https://en.wikipedia.org/w/index.php?\" + lbl_wikipedia\n",
    "            display(Markdown(\"&ensp;&ensp;&ensp;{} {}\".format(google_link, wikipedia_link)))\n",
    "\n",
    "    print(\"\\n\")\n",
    "    display(Markdown(\"***Known answers from the testset:***\"))\n",
    "    known_answers = []\n",
    "    for triple in raw_test_triples:\n",
    "        if triple[2] == rel:\n",
    "            if typ == 0 and triple[1] == ent:\n",
    "                known_answers.append(triple[0])\n",
    "            if typ == 1 and triple[0] == ent:\n",
    "                known_answers.append(triple[1])\n",
    "    assert(len(known_answers) > 0)\n",
    "    for known_answer in known_answers:\n",
    "        lbl, link_wikidata = (ent_labels[known_answer],'')\n",
    "        a_str = lbl\n",
    "        desc = \"{} ({})\".format(a_str, known_answer)\n",
    "        print(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the annotation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88da110e8034dcf9b514f09577ee248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black', padding='5px'), outputs=({'name': 'stdout', 'text': 'Processed …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3454b30e17043aaa312cdfea9264be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle(font_weight='bf'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919471248ea24659a1ff05d893c4b41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Skip', style=ButtonStyle(font_weight='bf'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out.clear_output()\n",
    "ok = pick_next_query()\n",
    "with out:    \n",
    "    if ok is not None:\n",
    "        query = queries[current_query_id]\n",
    "        print_query_answers(query['id'], query['type'], query['ent'], query['rel'], query['answers'])\n",
    "b = widgets.Button(description='Submit', style=ButtonStyle(font_weight='bf'))\n",
    "b.on_click(on_click_button)\n",
    "b_skip = widgets.Button(description='Skip', style=ButtonStyle(font_weight='bf'))\n",
    "b_skip.on_click(on_click_skip_button)\n",
    "display(out)\n",
    "display(b)\n",
    "display(b_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
